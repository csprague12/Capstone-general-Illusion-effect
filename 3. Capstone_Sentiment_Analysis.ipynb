{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <b> purpose</b> of this notebook is to explore sentiment analysis using text blob and vedar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/celinasprague/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (3,4,5,10,43) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer \n",
    "import re\n",
    "from textblob import TextBlob\n",
    "import matplotlib.pyplot as plt\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "df = pd.read_csv('finaldata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Using TextBlob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We replace \"NA\" values, \"removed,\" and \"deleted\" with an empty string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].fillna('')\n",
    "tbr = ['[removed]', '[deleted]']\n",
    "df['text'] = df['text'].apply(lambda x: '' if x in tbr else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all the string to lower cases\n",
    "df['text'] = df['text'].str.lower()\n",
    "\n",
    "# \\S+ means anything that is not an empty space\n",
    "df['text'] = df['text'].apply(lambda x: re.sub('http\\S*', '', x))\n",
    "\n",
    "# \\s+ means all empty space (\\n, \\r, \\t)\n",
    "df['text'] = df['text'].apply(lambda x: re.sub('\\s+', ' ', x))\n",
    "\n",
    "# We don't want empty string in our text\n",
    "df = df.loc[df['text'] != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing punctuation\n",
    "df['text'] = df['text'].apply(lambda x: re.sub('[^\\w\\s]', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The function below removes stop words\n",
    "\n",
    "def sentiment_func(text):\n",
    "    try:\n",
    "        return TextBlob(text).sentiment\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_blob']= df['text'].apply(sentiment_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['polarity','subjectivity']]= df['text'].apply(lambda text:pd.Series(TextBlob(text).sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Unnamed: 0',\n",
       " 'author',\n",
       " 'crawled',\n",
       " 'entities_locations',\n",
       " 'entities_organizations',\n",
       " 'entities_persons',\n",
       " 'external_links',\n",
       " 'highlightText',\n",
       " 'highlightTitle',\n",
       " 'language',\n",
       " 'locations',\n",
       " 'ord_in_thread',\n",
       " 'organizations',\n",
       " 'persons',\n",
       " 'published',\n",
       " 'text',\n",
       " 'thread_country',\n",
       " 'thread_main_image',\n",
       " 'thread_participants_count',\n",
       " 'thread_performance_score',\n",
       " 'thread_published',\n",
       " 'thread_replies_count',\n",
       " 'thread_section_title',\n",
       " 'thread_site',\n",
       " 'thread_site_full',\n",
       " 'thread_site_section',\n",
       " 'thread_site_type',\n",
       " 'thread_social_facebook_comments',\n",
       " 'thread_social_facebook_likes',\n",
       " 'thread_social_facebook_shares',\n",
       " 'thread_social_gplus_shares',\n",
       " 'thread_social_linkedin_shares',\n",
       " 'thread_social_pinterest_shares',\n",
       " 'thread_social_stumbledupon_shares',\n",
       " 'thread_social_vk_shares',\n",
       " 'thread_spam_score',\n",
       " 'thread_title',\n",
       " 'thread_title_full',\n",
       " 'thread_url',\n",
       " 'thread_uuid',\n",
       " 'title',\n",
       " 'url',\n",
       " 'uuid',\n",
       " 'thread_domain_rank',\n",
       " 'text_blob',\n",
       " 'polarity',\n",
       " 'subjectivity']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentimentdata = df.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentimentdata.to_csv('sentimentdata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Using Vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/celinasprague/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (3,4,5,10,43) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv('finaldata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill na with empty string\n",
    "df1['text'] = df1['text'].fillna('')\n",
    "# Replace `removed` and `deleted` with empty string\n",
    "tbr = ['[removed]', '[deleted]']\n",
    "df1['text'] = df1['text'].apply(lambda x: '' if x in tbr else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text=df1['text']\n",
    "all_sent_values=[]\n",
    "all_sentiments=[]\n",
    "\n",
    "def sentiment_value(paragraph):\n",
    "    analyser= SentimentIntensityAnalyzer()\n",
    "    result= analyser.polarity_scores(paragraph)\n",
    "    score=result['compound']\n",
    "    return round(score ,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Warning!\n",
    "Code below might take some time to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There have been 5000 files read so far\n",
      "Time elapsed: 71.21340823173523\n",
      "There have been 10000 files read so far\n",
      "Time elapsed: 143.90734815597534\n",
      "There have been 15000 files read so far\n",
      "Time elapsed: 215.8674340248108\n",
      "There have been 20000 files read so far\n",
      "Time elapsed: 288.4437482357025\n",
      "There have been 25000 files read so far\n",
      "Time elapsed: 360.16496109962463\n",
      "There have been 30000 files read so far\n",
      "Time elapsed: 430.4718053340912\n",
      "There have been 35000 files read so far\n",
      "Time elapsed: 498.0337710380554\n",
      "There have been 40000 files read so far\n",
      "Time elapsed: 563.2042272090912\n",
      "There have been 45000 files read so far\n",
      "Time elapsed: 637.4129903316498\n",
      "There have been 50000 files read so far\n",
      "Time elapsed: 712.1230063438416\n",
      "There have been 55000 files read so far\n",
      "Time elapsed: 784.1697692871094\n",
      "There have been 60000 files read so far\n",
      "Time elapsed: 850.0583682060242\n",
      "There have been 65000 files read so far\n",
      "Time elapsed: 915.6351401805878\n",
      "There have been 70000 files read so far\n",
      "Time elapsed: 980.647458076477\n",
      "There have been 75000 files read so far\n",
      "Time elapsed: 1045.2350080013275\n",
      "There have been 80000 files read so far\n",
      "Time elapsed: 1115.420491218567\n",
      "There have been 85000 files read so far\n",
      "Time elapsed: 1210.2091882228851\n",
      "There have been 90000 files read so far\n",
      "Time elapsed: 1334.8653161525726\n",
      "There have been 95000 files read so far\n",
      "Time elapsed: 1440.83642911911\n",
      "There have been 100000 files read so far\n",
      "Time elapsed: 1559.5699381828308\n",
      "There have been 105000 files read so far\n",
      "Time elapsed: 1674.9113092422485\n",
      "There have been 110000 files read so far\n",
      "Time elapsed: 1794.019466161728\n",
      "There have been 115000 files read so far\n",
      "Time elapsed: 1898.6132581233978\n",
      "There have been 120000 files read so far\n",
      "Time elapsed: 2003.6172721385956\n",
      "There have been 125000 files read so far\n",
      "Time elapsed: 2108.1206452846527\n",
      "There have been 130000 files read so far\n",
      "Time elapsed: 2230.4129474163055\n",
      "There have been 135000 files read so far\n",
      "Time elapsed: 2334.6485340595245\n",
      "There have been 140000 files read so far\n",
      "Time elapsed: 2438.479023218155\n",
      "There have been 145000 files read so far\n",
      "Time elapsed: 2542.666768312454\n",
      "There have been 150000 files read so far\n",
      "Time elapsed: 2647.0893173217773\n",
      "There have been 155000 files read so far\n",
      "Time elapsed: 2778.9685492515564\n",
      "There have been 160000 files read so far\n",
      "Time elapsed: 2908.765792131424\n",
      "There have been 165000 files read so far\n",
      "Time elapsed: 3044.0116562843323\n",
      "There have been 170000 files read so far\n",
      "Time elapsed: 3193.805071115494\n",
      "Operation complete after 3324.3857741355896 seconds.\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(0,len(df1)):\n",
    "    all_sent_values.append(sentiment_value(all_text[i]))\n",
    "    \n",
    "    counter += 1\n",
    "    \n",
    "    if counter % 5000 == 0:\n",
    "        print(\"There have been {} files read so far\".format(counter))\n",
    "        print(\"Time elapsed: {}\".format(time.time() - start_time))\n",
    "        \n",
    " \n",
    "    \n",
    "print(\"Operation complete after {} seconds.\".format(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(173313, 44)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_data = df1\n",
    "temp_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There have been 5000 files read so far\n",
      "Time elapsed: 0.01027989387512207\n",
      "There have been 10000 files read so far\n",
      "Time elapsed: 0.015654802322387695\n",
      "There have been 15000 files read so far\n",
      "Time elapsed: 0.02219390869140625\n",
      "There have been 20000 files read so far\n",
      "Time elapsed: 0.03348803520202637\n",
      "There have been 25000 files read so far\n",
      "Time elapsed: 0.03943896293640137\n",
      "There have been 30000 files read so far\n",
      "Time elapsed: 0.04516196250915527\n",
      "There have been 35000 files read so far\n",
      "Time elapsed: 0.0518031120300293\n",
      "There have been 40000 files read so far\n",
      "Time elapsed: 0.05954718589782715\n",
      "There have been 45000 files read so far\n",
      "Time elapsed: 0.06949806213378906\n",
      "There have been 50000 files read so far\n",
      "Time elapsed: 0.08312010765075684\n",
      "There have been 55000 files read so far\n",
      "Time elapsed: 0.09449291229248047\n",
      "There have been 60000 files read so far\n",
      "Time elapsed: 0.1025838851928711\n",
      "There have been 65000 files read so far\n",
      "Time elapsed: 0.10884881019592285\n",
      "There have been 70000 files read so far\n",
      "Time elapsed: 0.11557388305664062\n",
      "There have been 75000 files read so far\n",
      "Time elapsed: 0.12440800666809082\n",
      "There have been 80000 files read so far\n",
      "Time elapsed: 0.13049077987670898\n",
      "There have been 85000 files read so far\n",
      "Time elapsed: 0.1356799602508545\n",
      "There have been 90000 files read so far\n",
      "Time elapsed: 0.14092278480529785\n",
      "There have been 95000 files read so far\n",
      "Time elapsed: 0.1469869613647461\n",
      "There have been 100000 files read so far\n",
      "Time elapsed: 0.15507888793945312\n",
      "There have been 105000 files read so far\n",
      "Time elapsed: 0.16043901443481445\n",
      "There have been 110000 files read so far\n",
      "Time elapsed: 0.16559886932373047\n",
      "There have been 115000 files read so far\n",
      "Time elapsed: 0.17082786560058594\n",
      "There have been 120000 files read so far\n",
      "Time elapsed: 0.17623591423034668\n",
      "There have been 125000 files read so far\n",
      "Time elapsed: 0.1823720932006836\n",
      "There have been 130000 files read so far\n",
      "Time elapsed: 0.1874070167541504\n",
      "There have been 135000 files read so far\n",
      "Time elapsed: 0.19260096549987793\n",
      "There have been 140000 files read so far\n",
      "Time elapsed: 0.19783282279968262\n",
      "There have been 145000 files read so far\n",
      "Time elapsed: 0.20314908027648926\n",
      "There have been 150000 files read so far\n",
      "Time elapsed: 0.20845699310302734\n",
      "There have been 155000 files read so far\n",
      "Time elapsed: 0.2138369083404541\n",
      "There have been 160000 files read so far\n",
      "Time elapsed: 0.21909809112548828\n",
      "There have been 165000 files read so far\n",
      "Time elapsed: 0.22437405586242676\n",
      "There have been 170000 files read so far\n",
      "Time elapsed: 0.22989988327026367\n",
      "Operation complete after 0.2335829734802246 seconds.\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "start_time = time.time()\n",
    "\n",
    "SENTIMENT_VALUE = []\n",
    "SENTIMENT = []\n",
    "for i in range(0,len(df1)):\n",
    "    sent = all_sent_values[i]\n",
    "    if (sent<=1 and sent>=0.5):\n",
    "        SENTIMENT.append('V.Positive')\n",
    "        SENTIMENT_VALUE.append(5)\n",
    "    elif (sent<0.5 and sent>0):\n",
    "        SENTIMENT.append('Positive')\n",
    "        SENTIMENT_VALUE.append(4)\n",
    "    elif (sent==0):\n",
    "        SENTIMENT.append('Neutral')\n",
    "        SENTIMENT_VALUE.append(3)\n",
    "    elif (sent<0 and sent>=-0.5):\n",
    "        SENTIMENT.append('Negative')\n",
    "        SENTIMENT_VALUE.append(2)\n",
    "    else:\n",
    "        SENTIMENT.append('V.Negative')\n",
    "        SENTIMENT_VALUE.append(1)\n",
    "        \n",
    "    counter += 1\n",
    "    \n",
    "    if counter % 5000 == 0:\n",
    "        print(\"There have been {} files read so far\".format(counter))\n",
    "        print(\"Time elapsed: {}\".format(time.time() - start_time))\n",
    "        \n",
    " \n",
    "    \n",
    "print(\"Operation complete after {} seconds.\".format(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update to temp dataset\n",
    "temp_data['SENTIMENT_VALUE'] = SENTIMENT_VALUE\n",
    "temp_data['SENTIMENT'] = SENTIMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "vedardata = temp_data.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>crawled</th>\n",
       "      <th>entities_locations</th>\n",
       "      <th>entities_organizations</th>\n",
       "      <th>entities_persons</th>\n",
       "      <th>external_links</th>\n",
       "      <th>highlightText</th>\n",
       "      <th>highlightTitle</th>\n",
       "      <th>language</th>\n",
       "      <th>locations</th>\n",
       "      <th>...</th>\n",
       "      <th>thread_title</th>\n",
       "      <th>thread_title_full</th>\n",
       "      <th>thread_url</th>\n",
       "      <th>thread_uuid</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>uuid</th>\n",
       "      <th>thread_domain_rank</th>\n",
       "      <th>SENTIMENT_VALUE</th>\n",
       "      <th>SENTIMENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USNews</td>\n",
       "      <td>2015-10-02T17:33:59.981+03:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[['http://www.reddit.com/submit?url=http%3A%2F...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>english</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>The Healthiest Pastas: From Quinoa to Buckwhea...</td>\n",
       "      <td>The Healthiest Pastas: From Quinoa to Buckwhea...</td>\n",
       "      <td>http://health.usnews.com/health-news/health-we...</td>\n",
       "      <td>8085f289866a814f7a443e1a31e48f8a307a040f</td>\n",
       "      <td>The Healthiest Pastas: From Quinoa to Buckwhea...</td>\n",
       "      <td>http://health.usnews.com/health-news/health-we...</td>\n",
       "      <td>8085f289866a814f7a443e1a31e48f8a307a040f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>V.Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-10-19T09:23:00.540+03:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>english</td>\n",
       "      <td>['Savoonga']</td>\n",
       "      <td>...</td>\n",
       "      <td>Photos: Operation Santa Claus visits Savoonga</td>\n",
       "      <td>Photos: Operation Santa Claus visits Savoonga</td>\n",
       "      <td>http://www.newsdump.com/article/photos-operati...</td>\n",
       "      <td>f4ad43deab0a72726d6165b37a971c578efdd4f5</td>\n",
       "      <td>Photos: Operation Santa Claus visits Savoonga</td>\n",
       "      <td>http://www.newsdump.com/article/photos-operati...</td>\n",
       "      <td>f4ad43deab0a72726d6165b37a971c578efdd4f5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-10-08T17:42:28.717+03:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>english</td>\n",
       "      <td>['Palmyra']</td>\n",
       "      <td>...</td>\n",
       "      <td>Watch: Video Shows 2,000-Year-Old Ancient Arch...</td>\n",
       "      <td>Watch: Video Shows 2,000-Year-Old Ancient Arch...</td>\n",
       "      <td>http://www.newsdump.com/article/watch-video-sh...</td>\n",
       "      <td>c98cbd870f52950ff685e772fd189bd01fc85767</td>\n",
       "      <td>Watch: Video Shows 2,000-Year-Old Ancient Arch...</td>\n",
       "      <td>http://www.newsdump.com/article/watch-video-sh...</td>\n",
       "      <td>c98cbd870f52950ff685e772fd189bd01fc85767</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-10-05T10:10:00.218+03:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>english</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>'Fear the Walking Dead' ends Season 1 on a gri...</td>\n",
       "      <td>'Fear the Walking Dead' ends Season 1 on a gri...</td>\n",
       "      <td>http://www.newsdump.com/article/fear-the-walki...</td>\n",
       "      <td>3481ad311613e0da31e6017f854c7ded093b398a</td>\n",
       "      <td>'Fear the Walking Dead' ends Season 1 on a gri...</td>\n",
       "      <td>http://www.newsdump.com/article/fear-the-walki...</td>\n",
       "      <td>3481ad311613e0da31e6017f854c7ded093b398a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>V.Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-10-23T15:40:06.454+03:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>english</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Facebook app draining your iPhone battery? Com...</td>\n",
       "      <td>Facebook app draining your iPhone battery? Com...</td>\n",
       "      <td>http://www.newsdump.com/article/facebook-app-d...</td>\n",
       "      <td>17954912c005732967b28ef81b4ebc58d3911efc</td>\n",
       "      <td>Facebook app draining your iPhone battery? Com...</td>\n",
       "      <td>http://www.newsdump.com/article/facebook-app-d...</td>\n",
       "      <td>17954912c005732967b28ef81b4ebc58d3911efc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   author                        crawled entities_locations  \\\n",
       "0  USNews  2015-10-02T17:33:59.981+03:00                NaN   \n",
       "1     NaN  2015-10-19T09:23:00.540+03:00                NaN   \n",
       "2     NaN  2015-10-08T17:42:28.717+03:00                NaN   \n",
       "3     NaN  2015-10-05T10:10:00.218+03:00                NaN   \n",
       "4     NaN  2015-10-23T15:40:06.454+03:00                NaN   \n",
       "\n",
       "  entities_organizations entities_persons  \\\n",
       "0                    NaN              NaN   \n",
       "1                    NaN              NaN   \n",
       "2                    NaN              NaN   \n",
       "3                    NaN              NaN   \n",
       "4                    NaN              NaN   \n",
       "\n",
       "                                      external_links  highlightText  \\\n",
       "0  [['http://www.reddit.com/submit?url=http%3A%2F...            NaN   \n",
       "1                                                NaN            NaN   \n",
       "2                                                NaN            NaN   \n",
       "3                                                NaN            NaN   \n",
       "4                                                NaN            NaN   \n",
       "\n",
       "   highlightTitle language     locations     ...      \\\n",
       "0             NaN  english           NaN     ...       \n",
       "1             NaN  english  ['Savoonga']     ...       \n",
       "2             NaN  english   ['Palmyra']     ...       \n",
       "3             NaN  english           NaN     ...       \n",
       "4             NaN  english           NaN     ...       \n",
       "\n",
       "                                        thread_title  \\\n",
       "0  The Healthiest Pastas: From Quinoa to Buckwhea...   \n",
       "1      Photos: Operation Santa Claus visits Savoonga   \n",
       "2  Watch: Video Shows 2,000-Year-Old Ancient Arch...   \n",
       "3  'Fear the Walking Dead' ends Season 1 on a gri...   \n",
       "4  Facebook app draining your iPhone battery? Com...   \n",
       "\n",
       "                                   thread_title_full  \\\n",
       "0  The Healthiest Pastas: From Quinoa to Buckwhea...   \n",
       "1      Photos: Operation Santa Claus visits Savoonga   \n",
       "2  Watch: Video Shows 2,000-Year-Old Ancient Arch...   \n",
       "3  'Fear the Walking Dead' ends Season 1 on a gri...   \n",
       "4  Facebook app draining your iPhone battery? Com...   \n",
       "\n",
       "                                          thread_url  \\\n",
       "0  http://health.usnews.com/health-news/health-we...   \n",
       "1  http://www.newsdump.com/article/photos-operati...   \n",
       "2  http://www.newsdump.com/article/watch-video-sh...   \n",
       "3  http://www.newsdump.com/article/fear-the-walki...   \n",
       "4  http://www.newsdump.com/article/facebook-app-d...   \n",
       "\n",
       "                                thread_uuid  \\\n",
       "0  8085f289866a814f7a443e1a31e48f8a307a040f   \n",
       "1  f4ad43deab0a72726d6165b37a971c578efdd4f5   \n",
       "2  c98cbd870f52950ff685e772fd189bd01fc85767   \n",
       "3  3481ad311613e0da31e6017f854c7ded093b398a   \n",
       "4  17954912c005732967b28ef81b4ebc58d3911efc   \n",
       "\n",
       "                                               title  \\\n",
       "0  The Healthiest Pastas: From Quinoa to Buckwhea...   \n",
       "1      Photos: Operation Santa Claus visits Savoonga   \n",
       "2  Watch: Video Shows 2,000-Year-Old Ancient Arch...   \n",
       "3  'Fear the Walking Dead' ends Season 1 on a gri...   \n",
       "4  Facebook app draining your iPhone battery? Com...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  http://health.usnews.com/health-news/health-we...   \n",
       "1  http://www.newsdump.com/article/photos-operati...   \n",
       "2  http://www.newsdump.com/article/watch-video-sh...   \n",
       "3  http://www.newsdump.com/article/fear-the-walki...   \n",
       "4  http://www.newsdump.com/article/facebook-app-d...   \n",
       "\n",
       "                                       uuid  thread_domain_rank  \\\n",
       "0  8085f289866a814f7a443e1a31e48f8a307a040f                 NaN   \n",
       "1  f4ad43deab0a72726d6165b37a971c578efdd4f5                 NaN   \n",
       "2  c98cbd870f52950ff685e772fd189bd01fc85767                 NaN   \n",
       "3  3481ad311613e0da31e6017f854c7ded093b398a                 NaN   \n",
       "4  17954912c005732967b28ef81b4ebc58d3911efc                 NaN   \n",
       "\n",
       "   SENTIMENT_VALUE   SENTIMENT  \n",
       "0                5  V.Positive  \n",
       "1                3     Neutral  \n",
       "2                3     Neutral  \n",
       "3                1  V.Negative  \n",
       "4                3     Neutral  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vedardata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "vedardata.to_csv('vedardata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = temp_data[['text','SENTIMENT','SENTIMENT_VALUE']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
